Starting training...
Epoch 1 of 2000 took 1.608s
  training loss:		0.096047
  validation loss:		0.089154
  validation accuracy:		27.40000 %
Epoch 2 of 2000 took 1.604s
  training loss:		0.085882
  validation loss:		0.084172
  validation accuracy:		32.52000 %
Epoch 3 of 2000 took 1.594s
  training loss:		0.083102
  validation loss:		0.082329
  validation accuracy:		34.64000 %
Epoch 4 of 2000 took 1.602s
  training loss:		0.081776
  validation loss:		0.081373
  validation accuracy:		35.46000 %
Epoch 5 of 2000 took 1.600s
  training loss:		0.080850
  validation loss:		0.080371
  validation accuracy:		37.30000 %
Epoch 6 of 2000 took 1.615s
  training loss:		0.080102
  validation loss:		0.079592
  validation accuracy:		38.28000 %
Epoch 7 of 2000 took 1.642s
  training loss:		0.079530
  validation loss:		0.079239
  validation accuracy:		38.21999 %
Epoch 8 of 2000 took 1.618s
  training loss:		0.079075
  validation loss:		0.078992
  validation accuracy:		38.38000 %
Epoch 9 of 2000 took 1.596s
  training loss:		0.078667
  validation loss:		0.078663
  validation accuracy:		39.05999 %
Epoch 10 of 2000 took 1.596s
  training loss:		0.078323
  validation loss:		0.078401
  validation accuracy:		39.79999 %
Epoch 11 of 2000 took 1.593s
  training loss:		0.077995
  validation loss:		0.078146
  validation accuracy:		39.92001 %
Epoch 12 of 2000 took 1.611s
  training loss:		0.077700
  validation loss:		0.077998
  validation accuracy:		40.32000 %
Epoch 13 of 2000 took 1.593s
  training loss:		0.077424
  validation loss:		0.077905
  validation accuracy:		40.30000 %
Epoch 14 of 2000 took 1.591s
  training loss:		0.077176
  validation loss:		0.077650
  validation accuracy:		40.88000 %
Epoch 15 of 2000 took 1.604s
  training loss:		0.076937
  validation loss:		0.077533
  validation accuracy:		41.34000 %
Epoch 16 of 2000 took 1.605s
  training loss:		0.076718
  validation loss:		0.077402
  validation accuracy:		41.62001 %
Epoch 17 of 2000 took 1.601s
  training loss:		0.076516
  validation loss:		0.077246
  validation accuracy:		42.02000 %
Epoch 18 of 2000 took 1.598s
  training loss:		0.076321
  validation loss:		0.077116
  validation accuracy:		42.19999 %
Epoch 19 of 2000 took 1.605s
  training loss:		0.076150
  validation loss:		0.076986
  validation accuracy:		42.39999 %
Epoch 20 of 2000 took 1.603s
  training loss:		0.075985
  validation loss:		0.076829
  validation accuracy:		42.29999 %
Epoch 21 of 2000 took 1.612s
  training loss:		0.075829
  validation loss:		0.076707
  validation accuracy:		42.38000 %
Epoch 22 of 2000 took 1.593s
  training loss:		0.075686
  validation loss:		0.076626
  validation accuracy:		42.47999 %
Epoch 23 of 2000 took 1.617s
  training loss:		0.075548
  validation loss:		0.076493
  validation accuracy:		42.72000 %
Epoch 24 of 2000 took 1.594s
  training loss:		0.075416
  validation loss:		0.076448
  validation accuracy:		42.86000 %
Epoch 25 of 2000 took 1.589s
  training loss:		0.075289
  validation loss:		0.076330
  validation accuracy:		43.08000 %
Epoch 26 of 2000 took 1.590s
  training loss:		0.075170
  validation loss:		0.076273
  validation accuracy:		43.08000 %
Epoch 27 of 2000 took 1.589s
  training loss:		0.075064
  validation loss:		0.076184
  validation accuracy:		43.25999 %
Epoch 28 of 2000 took 1.613s
  training loss:		0.074946
  validation loss:		0.076080
  validation accuracy:		43.60000 %
Epoch 29 of 2000 took 1.603s
  training loss:		0.074833
  validation loss:		0.075948
  validation accuracy:		43.69999 %
Epoch 30 of 2000 took 1.612s
  training loss:		0.074719
  validation loss:		0.075865
  validation accuracy:		43.94000 %
Epoch 31 of 2000 took 1.605s
  training loss:		0.074612
  validation loss:		0.075772
  validation accuracy:		44.12000 %
Epoch 32 of 2000 took 1.599s
  training loss:		0.074515
  validation loss:		0.075787
  validation accuracy:		43.99999 %
Epoch 33 of 2000 took 1.609s
  training loss:		0.074412
  validation loss:		0.075753
  validation accuracy:		44.01999 %
Epoch 34 of 2000 took 1.596s
  training loss:		0.074317
  validation loss:		0.075665
  validation accuracy:		44.16000 %
Epoch 35 of 2000 took 1.589s
  training loss:		0.074225
  validation loss:		0.075614
  validation accuracy:		44.05999 %
Epoch 36 of 2000 took 1.591s
  training loss:		0.074131
  validation loss:		0.075592
  validation accuracy:		43.89999 %
Epoch 37 of 2000 took 1.591s
  training loss:		0.074044
  validation loss:		0.075514
  validation accuracy:		44.02000 %
Epoch 38 of 2000 took 1.590s
  training loss:		0.073958
  validation loss:		0.075451
  validation accuracy:		44.12000 %
Epoch 39 of 2000 took 1.601s
  training loss:		0.073879
  validation loss:		0.075435
  validation accuracy:		44.22000 %
Epoch 40 of 2000 took 1.596s
  training loss:		0.073792
  validation loss:		0.075394
  validation accuracy:		44.18000 %
Epoch 41 of 2000 took 1.612s
  training loss:		0.073724
  validation loss:		0.075305
  validation accuracy:		44.41999 %
Epoch 42 of 2000 took 1.609s
  training loss:		0.073646
  validation loss:		0.075301
  validation accuracy:		44.39999 %
Epoch 43 of 2000 took 1.606s
  training loss:		0.073576
  validation loss:		0.075243
  validation accuracy:		44.43999 %
Epoch 44 of 2000 took 1.591s
  training loss:		0.073512
  validation loss:		0.075187
  validation accuracy:		44.48000 %
Epoch 45 of 2000 took 1.593s
  training loss:		0.073448
  validation loss:		0.075160
  validation accuracy:		44.52000 %
Epoch 46 of 2000 took 1.593s
  training loss:		0.073375
  validation loss:		0.075160
  validation accuracy:		44.62000 %
Epoch 47 of 2000 took 1.590s
  training loss:		0.073310
  validation loss:		0.075121
  validation accuracy:		44.80000 %
Epoch 48 of 2000 took 1.593s
  training loss:		0.073248
  validation loss:		0.075122
  validation accuracy:		44.90001 %
Epoch 49 of 2000 took 1.590s
  training loss:		0.073184
  validation loss:		0.075068
  validation accuracy:		44.82000 %
Epoch 50 of 2000 took 1.588s
  training loss:		0.073122
  validation loss:		0.075103
  validation accuracy:		44.80000 %
Epoch 51 of 2000 took 1.592s
  training loss:		0.073064
  validation loss:		0.075053
  validation accuracy:		44.84001 %
Epoch 52 of 2000 took 1.590s
  training loss:		0.073005
  validation loss:		0.075028
  validation accuracy:		45.02000 %
Epoch 53 of 2000 took 1.602s
  training loss:		0.072943
  validation loss:		0.075001
  validation accuracy:		45.04000 %
Epoch 54 of 2000 took 1.590s
  training loss:		0.072883
  validation loss:		0.074950
  validation accuracy:		45.02000 %
Epoch 55 of 2000 took 1.593s
  training loss:		0.072830
  validation loss:		0.074930
  validation accuracy:		45.06000 %
Epoch 56 of 2000 took 1.589s
  training loss:		0.072774
  validation loss:		0.074898
  validation accuracy:		45.12000 %
Epoch 57 of 2000 took 1.599s
  training loss:		0.072722
  validation loss:		0.074890
  validation accuracy:		45.09999 %
Epoch 58 of 2000 took 1.594s
  training loss:		0.072664
  validation loss:		0.074850
  validation accuracy:		45.16000 %
Epoch 59 of 2000 took 1.618s
  training loss:		0.072614
  validation loss:		0.074811
  validation accuracy:		45.16000 %
Epoch 60 of 2000 took 1.620s
  training loss:		0.072557
  validation loss:		0.074778
  validation accuracy:		45.28000 %
Epoch 61 of 2000 took 1.598s
  training loss:		0.072508
  validation loss:		0.074716
  validation accuracy:		45.46000 %
Epoch 62 of 2000 took 1.600s
  training loss:		0.072453
  validation loss:		0.074689
  validation accuracy:		45.42000 %
Epoch 63 of 2000 took 1.597s
  training loss:		0.072403
  validation loss:		0.074690
  validation accuracy:		45.30000 %
Epoch 64 of 2000 took 1.605s
  training loss:		0.072351
  validation loss:		0.074651
  validation accuracy:		45.44000 %
Epoch 65 of 2000 took 1.595s
  training loss:		0.072299
  validation loss:		0.074648
  validation accuracy:		45.48000 %
Epoch 66 of 2000 took 1.607s
  training loss:		0.072255
  validation loss:		0.074616
  validation accuracy:		45.52000 %
Epoch 67 of 2000 took 1.598s
  training loss:		0.072206
  validation loss:		0.074599
  validation accuracy:		45.45999 %
Epoch 68 of 2000 took 1.593s
  training loss:		0.072155
  validation loss:		0.074560
  validation accuracy:		45.60000 %
Epoch 69 of 2000 took 1.608s
  training loss:		0.072106
  validation loss:		0.074515
  validation accuracy:		45.77999 %
Epoch 70 of 2000 took 1.597s
  training loss:		0.072054
  validation loss:		0.074517
  validation accuracy:		45.75999 %
Epoch 71 of 2000 took 1.596s
  training loss:		0.072005
  validation loss:		0.074456
  validation accuracy:		45.92000 %
Epoch 72 of 2000 took 1.604s
  training loss:		0.071961
  validation loss:		0.074426
  validation accuracy:		46.00000 %
Epoch 73 of 2000 took 1.608s
  training loss:		0.071913
  validation loss:		0.074437
  validation accuracy:		46.00000 %
Epoch 74 of 2000 took 1.596s
  training loss:		0.071866
  validation loss:		0.074414
  validation accuracy:		46.04000 %
Epoch 75 of 2000 took 1.611s
  training loss:		0.071823
  validation loss:		0.074366
  validation accuracy:		46.28000 %
Epoch 76 of 2000 took 1.606s
  training loss:		0.071781
  validation loss:		0.074311
  validation accuracy:		46.32000 %
Epoch 77 of 2000 took 1.603s
  training loss:		0.071739
  validation loss:		0.074283
  validation accuracy:		46.54000 %
Epoch 78 of 2000 took 1.590s
  training loss:		0.071699
  validation loss:		0.074293
  validation accuracy:		46.46000 %
Epoch 79 of 2000 took 1.588s
  training loss:		0.071656
  validation loss:		0.074227
  validation accuracy:		46.50000 %
Epoch 80 of 2000 took 1.588s
  training loss:		0.071612
  validation loss:		0.074203
  validation accuracy:		46.58000 %
Epoch 81 of 2000 took 1.592s
  training loss:		0.071573
  validation loss:		0.074205
  validation accuracy:		46.52000 %
Epoch 82 of 2000 took 1.592s
  training loss:		0.071529
  validation loss:		0.074146
  validation accuracy:		46.66000 %
Epoch 83 of 2000 took 1.591s
  training loss:		0.071490
  validation loss:		0.074116
  validation accuracy:		46.66000 %
Epoch 84 of 2000 took 1.593s
  training loss:		0.071453
  validation loss:		0.074121
  validation accuracy:		46.66000 %
Epoch 85 of 2000 took 1.590s
  training loss:		0.071412
  validation loss:		0.074098
  validation accuracy:		46.78000 %
Epoch 86 of 2000 took 1.588s
  training loss:		0.071375
  validation loss:		0.074080
  validation accuracy:		46.87999 %
Epoch 87 of 2000 took 1.588s
  training loss:		0.071337
  validation loss:		0.074066
  validation accuracy:		46.90000 %
Epoch 88 of 2000 took 1.591s
  training loss:		0.071300
  validation loss:		0.074049
  validation accuracy:		46.98000 %
Epoch 89 of 2000 took 1.589s
  training loss:		0.071264
  validation loss:		0.074012
  validation accuracy:		47.12000 %
Epoch 90 of 2000 took 1.588s
  training loss:		0.071221
  validation loss:		0.074004
  validation accuracy:		47.02000 %
Epoch 91 of 2000 took 1.589s
  training loss:		0.071184
  validation loss:		0.073988
  validation accuracy:		47.22000 %
Epoch 92 of 2000 took 1.590s
  training loss:		0.071153
  validation loss:		0.073968
  validation accuracy:		47.24000 %
Epoch 93 of 2000 took 1.603s
  training loss:		0.071113
  validation loss:		0.073962
  validation accuracy:		47.22000 %
Epoch 94 of 2000 took 1.603s
  training loss:		0.071076
  validation loss:		0.073943
  validation accuracy:		47.34000 %
Epoch 95 of 2000 took 1.590s
  training loss:		0.071043
  validation loss:		0.073934
  validation accuracy:		47.24000 %
Epoch 96 of 2000 took 1.591s
  training loss:		0.071007
  validation loss:		0.073931
  validation accuracy:		47.24000 %
Epoch 97 of 2000 took 1.590s
  training loss:		0.070977
  validation loss:		0.073913
  validation accuracy:		47.20000 %
Epoch 98 of 2000 took 1.594s
  training loss:		0.070943
  validation loss:		0.073896
  validation accuracy:		47.30000 %
Epoch 99 of 2000 took 1.588s
  training loss:		0.070908
  validation loss:		0.073898
  validation accuracy:		47.30000 %
Epoch 100 of 2000 took 1.591s
  training loss:		0.070875
  validation loss:		0.073875
  validation accuracy:		47.33999 %
Epoch 101 of 2000 took 1.591s
  training loss:		0.070846
  validation loss:		0.073881
  validation accuracy:		47.28000 %
Epoch 102 of 2000 took 1.589s
  training loss:		0.070812
  validation loss:		0.073889
  validation accuracy:		47.25999 %
Epoch 103 of 2000 took 1.595s
  training loss:		0.070782
  validation loss:		0.073879
  validation accuracy:		47.44000 %
Epoch 104 of 2000 took 1.621s
  training loss:		0.070750
  validation loss:		0.073844
  validation accuracy:		47.39999 %
Epoch 105 of 2000 took 1.604s
  training loss:		0.070718
  validation loss:		0.073851
  validation accuracy:		47.35999 %
Epoch 106 of 2000 took 1.603s
  training loss:		0.070687
  validation loss:		0.073823
  validation accuracy:		47.50000 %
Epoch 107 of 2000 took 1.597s
  training loss:		0.070651
  validation loss:		0.073827
  validation accuracy:		47.48000 %
Epoch 108 of 2000 took 1.598s
  training loss:		0.070624
  validation loss:		0.073821
  validation accuracy:		47.42000 %
Epoch 109 of 2000 took 1.593s
  training loss:		0.070593
  validation loss:		0.073782
  validation accuracy:		47.74000 %
Epoch 110 of 2000 took 1.602s
  training loss:		0.070561
  validation loss:		0.073784
  validation accuracy:		47.63999 %
Epoch 111 of 2000 took 1.629s
  training loss:		0.070530
  validation loss:		0.073752
  validation accuracy:		47.65999 %
Epoch 112 of 2000 took 1.602s
  training loss:		0.070495
  validation loss:		0.073759
  validation accuracy:		47.55999 %
Epoch 113 of 2000 took 1.600s
  training loss:		0.070466
  validation loss:		0.073752
  validation accuracy:		47.65999 %
Epoch 114 of 2000 took 1.604s
  training loss:		0.070435
  validation loss:		0.073714
  validation accuracy:		47.73999 %
Epoch 115 of 2000 took 1.600s
  training loss:		0.070404
  validation loss:		0.073742
  validation accuracy:		47.74000 %
Epoch 116 of 2000 took 1.615s
  training loss:		0.070376
  validation loss:		0.073742
  validation accuracy:		47.76000 %
Epoch 117 of 2000 took 1.599s
  training loss:		0.070344
  validation loss:		0.073704
  validation accuracy:		47.92000 %
Epoch 118 of 2000 took 1.596s
  training loss:		0.070317
  validation loss:		0.073685
  validation accuracy:		47.84000 %
Epoch 119 of 2000 took 1.621s
  training loss:		0.070286
  validation loss:		0.073704
  validation accuracy:		47.76001 %
Epoch 120 of 2000 took 1.601s
  training loss:		0.070259
  validation loss:		0.073713
  validation accuracy:		47.82001 %
Epoch 121 of 2000 took 1.635s
  training loss:		0.070229
  validation loss:		0.073675
  validation accuracy:		48.00000 %
Epoch 122 of 2000 took 1.608s
  training loss:		0.070202
  validation loss:		0.073670
  validation accuracy:		48.00000 %
Epoch 123 of 2000 took 1.602s
  training loss:		0.070174
  validation loss:		0.073697
  validation accuracy:		48.04000 %
Epoch 124 of 2000 took 1.610s
  training loss:		0.070145
  validation loss:		0.073687
  validation accuracy:		48.04001 %
Epoch 125 of 2000 took 1.608s
  training loss:		0.070117
  validation loss:		0.073699
  validation accuracy:		47.88001 %
Epoch 126 of 2000 took 1.599s
  training loss:		0.070093
  validation loss:		0.073690
  validation accuracy:		48.00000 %
Epoch 127 of 2000 took 1.613s
  training loss:		0.070067
  validation loss:		0.073674
  validation accuracy:		48.02001 %
Epoch 128 of 2000 took 1.630s
  training loss:		0.070041
  validation loss:		0.073683
  validation accuracy:		47.96000 %
Epoch 129 of 2000 took 1.620s
  training loss:		0.070011
  validation loss:		0.073679
  validation accuracy:		48.04001 %
Epoch 130 of 2000 took 1.610s
  training loss:		0.069988
  validation loss:		0.073691
  validation accuracy:		47.94001 %
Epoch 131 of 2000 took 1.602s
  training loss:		0.069960
  validation loss:		0.073671
  validation accuracy:		47.92000 %
Epoch 132 of 2000 took 1.615s
  training loss:		0.069935
  validation loss:		0.073671
  validation accuracy:		47.92000 %
Epoch 133 of 2000 took 1.599s
  training loss:		0.069910
  validation loss:		0.073662
  validation accuracy:		47.92000 %
Epoch 134 of 2000 took 1.602s
  training loss:		0.069885
  validation loss:		0.073673
  validation accuracy:		47.96000 %
Epoch 135 of 2000 took 1.606s
  training loss:		0.069864
  validation loss:		0.073675
  validation accuracy:		47.92000 %
Epoch 136 of 2000 took 1.596s
  training loss:		0.069839
  validation loss:		0.073687
  validation accuracy:		47.94001 %
Epoch 137 of 2000 took 1.608s
  training loss:		0.069814
  validation loss:		0.073694
  validation accuracy:		47.82000 %
Epoch 138 of 2000 took 1.609s
  training loss:		0.069788
  validation loss:		0.073671
  validation accuracy:		48.02000 %
Epoch 139 of 2000 took 1.607s
  training loss:		0.069765
  validation loss:		0.073660
  validation accuracy:		48.16000 %
Epoch 140 of 2000 took 1.603s
  training loss:		0.069742
  validation loss:		0.073683
  validation accuracy:		48.14000 %
Epoch 141 of 2000 took 1.625s
  training loss:		0.069718
  validation loss:		0.073692
  validation accuracy:		47.96001 %
Epoch 142 of 2000 took 1.633s
  training loss:		0.069696
  validation loss:		0.073691
  validation accuracy:		48.00000 %
Epoch 143 of 2000 took 1.613s
  training loss:		0.069673
  validation loss:		0.073663
  validation accuracy:		48.06001 %
Epoch 144 of 2000 took 1.603s
  training loss:		0.069649
  validation loss:		0.073680
  validation accuracy:		48.08001 %
Epoch 145 of 2000 took 1.614s
  training loss:		0.069632
  validation loss:		0.073663
  validation accuracy:		48.00001 %
Epoch 146 of 2000 took 1.609s
  training loss:		0.069608
  validation loss:		0.073694
  validation accuracy:		48.04001 %
Epoch 147 of 2000 took 1.613s
  training loss:		0.069587
  validation loss:		0.073693
  validation accuracy:		48.06001 %
Epoch 148 of 2000 took 1.621s
  training loss:		0.069563
  validation loss:		0.073661
  validation accuracy:		48.08001 %
Epoch 149 of 2000 took 1.601s
  training loss:		0.069539
  validation loss:		0.073676
  validation accuracy:		48.18001 %
Epoch 150 of 2000 took 1.643s
  training loss:		0.069517
  validation loss:		0.073671
  validation accuracy:		48.16000 %
Epoch 151 of 2000 took 1.610s
  training loss:		0.069499
  validation loss:		0.073683
  validation accuracy:		48.10001 %
Epoch 152 of 2000 took 1.606s
  training loss:		0.069477
  validation loss:		0.073671
  validation accuracy:		48.08000 %
Epoch 153 of 2000 took 1.613s
  training loss:		0.069452
  validation loss:		0.073668
  validation accuracy:		48.12000 %
Epoch 154 of 2000 took 1.608s
  training loss:		0.069435
  validation loss:		0.073676
  validation accuracy:		48.08000 %
Epoch 155 of 2000 took 1.597s
  training loss:		0.069413
  validation loss:		0.073669
  validation accuracy:		48.04000 %
Epoch 156 of 2000 took 1.597s
  training loss:		0.069393
  validation loss:		0.073664
  validation accuracy:		48.08000 %
Epoch 157 of 2000 took 1.596s
  training loss:		0.069367
  validation loss:		0.073673
  validation accuracy:		48.30000 %
Epoch 158 of 2000 took 1.598s
  training loss:		0.069351
  validation loss:		0.073683
  validation accuracy:		48.10001 %
Epoch 159 of 2000 took 1.618s
  training loss:		0.069330
  validation loss:		0.073664
  validation accuracy:		48.18000 %
Epoch 160 of 2000 took 1.604s
  training loss:		0.069311
  validation loss:		0.073666
  validation accuracy:		48.28000 %
Epoch 161 of 2000 took 1.592s
  training loss:		0.069290
  validation loss:		0.073665
  validation accuracy:		48.26000 %
Epoch 162 of 2000 took 1.611s
  training loss:		0.069272
  validation loss:		0.073662
  validation accuracy:		48.26000 %
Epoch 163 of 2000 took 1.628s
  training loss:		0.069249
  validation loss:		0.073673
  validation accuracy:		48.30000 %
Epoch 164 of 2000 took 1.614s
  training loss:		0.069233
  validation loss:		0.073664
  validation accuracy:		48.36000 %
Epoch 165 of 2000 took 1.603s
  training loss:		0.069215
  validation loss:		0.073671
  validation accuracy:		48.38000 %
Epoch 166 of 2000 took 1.604s
  training loss:		0.069195
  validation loss:		0.073693
  validation accuracy:		48.32000 %
Epoch 167 of 2000 took 1.611s
  training loss:		0.069174
  validation loss:		0.073698
  validation accuracy:		48.36000 %
Epoch 168 of 2000 took 1.602s
  training loss:		0.069158
  validation loss:		0.073669
  validation accuracy:		48.46000 %
Epoch 169 of 2000 took 1.600s
  training loss:		0.069139
  validation loss:		0.073697
  validation accuracy:		48.36000 %
Epoch 170 of 2000 took 1.604s
  training loss:		0.069122
  validation loss:		0.073704
  validation accuracy:		48.38000 %
Epoch 171 of 2000 took 1.602s
  training loss:		0.069102
  validation loss:		0.073699
  validation accuracy:		48.32000 %
Epoch 172 of 2000 took 1.605s
  training loss:		0.069083
  validation loss:		0.073700
  validation accuracy:		48.36000 %
Epoch 173 of 2000 took 1.595s
  training loss:		0.069065
  validation loss:		0.073703
  validation accuracy:		48.40001 %
Epoch 174 of 2000 took 1.597s
  training loss:		0.069048
  validation loss:		0.073706
  validation accuracy:		48.38000 %
Epoch 175 of 2000 took 1.591s
  training loss:		0.069030
  validation loss:		0.073710
  validation accuracy:		48.36000 %
Epoch 176 of 2000 took 1.591s
  training loss:		0.069012
  validation loss:		0.073723
  validation accuracy:		48.37999 %
Epoch 177 of 2000 took 1.590s
  training loss:		0.068992
  validation loss:		0.073718
  validation accuracy:		48.37999 %
Epoch 178 of 2000 took 1.600s
  training loss:		0.068977
  validation loss:		0.073718
  validation accuracy:		48.48000 %
Epoch 179 of 2000 took 1.610s
  training loss:		0.068958
  validation loss:		0.073724
  validation accuracy:		48.50000 %
Epoch 180 of 2000 took 1.601s
  training loss:		0.068942
  validation loss:		0.073734
  validation accuracy:		48.43999 %
Epoch 181 of 2000 took 1.602s
  training loss:		0.068922
  validation loss:		0.073738
  validation accuracy:		48.44001 %
Epoch 182 of 2000 took 1.612s
  training loss:		0.068906
  validation loss:		0.073735
  validation accuracy:		48.56000 %
Epoch 183 of 2000 took 1.597s
  training loss:		0.068892
  validation loss:		0.073734
  validation accuracy:		48.54000 %
Epoch 184 of 2000 took 1.619s
  training loss:		0.068876
  validation loss:		0.073739
  validation accuracy:		48.56000 %
Epoch 185 of 2000 took 1.604s
  training loss:		0.068858
  validation loss:		0.073748
  validation accuracy:		48.50000 %
Epoch 186 of 2000 took 1.614s
  training loss:		0.068842
  validation loss:		0.073742
  validation accuracy:		48.50000 %
Epoch 187 of 2000 took 1.619s
  training loss:		0.068825
  validation loss:		0.073742
  validation accuracy:		48.42001 %
Epoch 188 of 2000 took 1.596s
  training loss:		0.068807
  validation loss:		0.073734
  validation accuracy:		48.47999 %
Epoch 189 of 2000 took 1.601s
  training loss:		0.068791
  validation loss:		0.073739
  validation accuracy:		48.42000 %
Epoch 190 of 2000 took 1.602s
  training loss:		0.068773
  validation loss:		0.073708
  validation accuracy:		48.44000 %
Epoch 191 of 2000 took 1.603s
  training loss:		0.068756
  validation loss:		0.073722
  validation accuracy:		48.62000 %
Epoch 192 of 2000 took 1.616s
  training loss:		0.068740
  validation loss:		0.073724
  validation accuracy:		48.50000 %
Epoch 193 of 2000 took 1.597s
  training loss:		0.068721
  validation loss:		0.073724
  validation accuracy:		48.66000 %
Epoch 194 of 2000 took 1.607s
  training loss:		0.068705
  validation loss:		0.073736
  validation accuracy:		48.52000 %
Epoch 195 of 2000 took 1.614s
  training loss:		0.068690
  validation loss:		0.073721
  validation accuracy:		48.50001 %
Epoch 196 of 2000 took 1.594s
  training loss:		0.068674
  validation loss:		0.073736
  validation accuracy:		48.58000 %
Epoch 197 of 2000 took 1.651s
  training loss:		0.068658
  validation loss:		0.073727
  validation accuracy:		48.56000 %
Epoch 198 of 2000 took 1.610s
  training loss:		0.068646
  validation loss:		0.073728
  validation accuracy:		48.54001 %
Epoch 199 of 2000 took 1.611s
  training loss:		0.068628
  validation loss:		0.073726
  validation accuracy:		48.58000 %
Epoch 200 of 2000 took 1.604s
  training loss:		0.068608
  validation loss:		0.073736
  validation accuracy:		48.62000 %
Epoch 201 of 2000 took 1.601s
  training loss:		0.068596
  validation loss:		0.073755
  validation accuracy:		48.48001 %
Epoch 202 of 2000 took 1.608s
  training loss:		0.068579
  validation loss:		0.073740
  validation accuracy:		48.56000 %
Epoch 203 of 2000 took 1.599s
  training loss:		0.068566
  validation loss:		0.073737
  validation accuracy:		48.64001 %
Epoch 204 of 2000 took 1.592s
  training loss:		0.068551
  validation loss:		0.073727
  validation accuracy:		48.76001 %
Epoch 205 of 2000 took 1.616s
  training loss:		0.068535
  validation loss:		0.073738
  validation accuracy:		48.64000 %
Epoch 206 of 2000 took 1.619s
  training loss:		0.068522
  validation loss:		0.073741
  validation accuracy:		48.72001 %
Epoch 207 of 2000 took 1.603s
  training loss:		0.068507
  validation loss:		0.073745
  validation accuracy:		48.60000 %
Epoch 208 of 2000 took 1.607s
  training loss:		0.068494
  validation loss:		0.073757
  validation accuracy:		48.62001 %
Epoch 209 of 2000 took 1.598s
  training loss:		0.068477
  validation loss:		0.073761
  validation accuracy:		48.62001 %
Epoch 210 of 2000 took 1.610s
  training loss:		0.068464
  validation loss:		0.073753
  validation accuracy:		48.54001 %
Epoch 211 of 2000 took 1.597s
  training loss:		0.068448
  validation loss:		0.073760
  validation accuracy:		48.56000 %
Epoch 212 of 2000 took 1.604s
  training loss:		0.068434
  validation loss:		0.073766
  validation accuracy:		48.48001 %
Epoch 213 of 2000 took 1.601s
  training loss:		0.068420
  validation loss:		0.073772
  validation accuracy:		48.56000 %
Epoch 214 of 2000 took 1.593s
  training loss:		0.068404
  validation loss:		0.073753
  validation accuracy:		48.70000 %
Epoch 215 of 2000 took 1.607s
  training loss:		0.068388
  validation loss:		0.073787
  validation accuracy:		48.59999 %
Epoch 216 of 2000 took 1.618s
  training loss:		0.068373
  validation loss:		0.073754
  validation accuracy:		48.74000 %
Epoch 217 of 2000 took 1.604s
  training loss:		0.068360
  validation loss:		0.073760
  validation accuracy:		48.74000 %
Epoch 218 of 2000 took 1.609s
  training loss:		0.068349
  validation loss:		0.073779
  validation accuracy:		48.58000 %
Epoch 219 of 2000 took 1.606s
  training loss:		0.068335
  validation loss:		0.073748
  validation accuracy:		48.78000 %
Epoch 220 of 2000 took 1.597s
  training loss:		0.068322
  validation loss:		0.073764
  validation accuracy:		48.72000 %
Epoch 221 of 2000 took 1.605s
  training loss:		0.068307
  validation loss:		0.073766
  validation accuracy:		48.78000 %
Epoch 222 of 2000 took 1.606s
  training loss:		0.068294
  validation loss:		0.073757
  validation accuracy:		48.86000 %
Epoch 223 of 2000 took 1.619s
  training loss:		0.068279
  validation loss:		0.073764
  validation accuracy:		48.78000 %
Epoch 224 of 2000 took 1.618s
  training loss:		0.068264
  validation loss:		0.073771
  validation accuracy:		48.81999 %
Epoch 225 of 2000 took 1.602s
  training loss:		0.068251
  validation loss:		0.073779
  validation accuracy:		48.98001 %
Epoch 226 of 2000 took 1.595s
  training loss:		0.068239
  validation loss:		0.073788
  validation accuracy:		48.78001 %
Epoch 227 of 2000 took 1.595s
  training loss:		0.068229
  validation loss:		0.073774
  validation accuracy:		49.00000 %
Epoch 228 of 2000 took 1.614s
  training loss:		0.068214
  validation loss:		0.073773
  validation accuracy:		48.94000 %
Epoch 229 of 2000 took 1.596s
  training loss:		0.068199
  validation loss:		0.073778
  validation accuracy:		48.97999 %
Epoch 230 of 2000 took 1.588s
  training loss:		0.068187
  validation loss:		0.073794
  validation accuracy:		48.90000 %
Epoch 231 of 2000 took 1.591s
  training loss:		0.068174
  validation loss:		0.073785
  validation accuracy:		48.99999 %
Epoch 232 of 2000 took 1.587s
  training loss:		0.068158
  validation loss:		0.073780
  validation accuracy:		48.90000 %
Epoch 233 of 2000 took 1.592s
  training loss:		0.068145
  validation loss:		0.073775
  validation accuracy:		48.96000 %
Epoch 234 of 2000 took 1.592s
  training loss:		0.068131
  validation loss:		0.073788
  validation accuracy:		48.92000 %
Epoch 235 of 2000 took 1.609s
  training loss:		0.068121
  validation loss:		0.073791
  validation accuracy:		49.00000 %
Epoch 236 of 2000 took 1.589s
  training loss:		0.068105
  validation loss:		0.073789
  validation accuracy:		49.04000 %
Epoch 237 of 2000 took 1.601s
  training loss:		0.068094
  validation loss:		0.073812
  validation accuracy:		49.06000 %
Epoch 238 of 2000 took 1.603s
  training loss:		0.068083
  validation loss:		0.073812
  validation accuracy:		49.10001 %
Epoch 239 of 2000 took 1.594s
  training loss:		0.068072
  validation loss:		0.073803
  validation accuracy:		49.12000 %
Epoch 240 of 2000 took 1.592s
  training loss:		0.068056
  validation loss:		0.073807
  validation accuracy:		49.06000 %
Epoch 241 of 2000 took 1.588s
  training loss:		0.068042
  validation loss:		0.073808
  validation accuracy:		49.08000 %
Epoch 242 of 2000 took 1.609s
  training loss:		0.068033
  validation loss:		0.073782
  validation accuracy:		48.94000 %
Epoch 243 of 2000 took 1.590s
  training loss:		0.068016
  validation loss:		0.073800
  validation accuracy:		49.04000 %
Epoch 244 of 2000 took 1.588s
  training loss:		0.068005
  validation loss:		0.073799
  validation accuracy:		49.06000 %
Epoch 245 of 2000 took 1.589s
  training loss:		0.067991
  validation loss:		0.073787
  validation accuracy:		48.98000 %
Epoch 246 of 2000 took 1.588s
  training loss:		0.067980
  validation loss:		0.073810
  validation accuracy:		49.12000 %
Epoch 247 of 2000 took 1.589s
  training loss:		0.067966
  validation loss:		0.073806
  validation accuracy:		49.08000 %
Epoch 248 of 2000 took 1.589s
  training loss:		0.067955
  validation loss:		0.073788
  validation accuracy:		49.04000 %
Epoch 249 of 2000 took 1.588s
  training loss:		0.067943
  validation loss:		0.073808
  validation accuracy:		49.04000 %
Epoch 250 of 2000 took 1.589s
  training loss:		0.067931
  validation loss:		0.073812
  validation accuracy:		49.07999 %
Epoch 251 of 2000 took 1.588s
  training loss:		0.067920
  validation loss:		0.073802
  validation accuracy:		49.14000 %
Epoch 252 of 2000 took 1.593s
  training loss:		0.067910
  validation loss:		0.073791
  validation accuracy:		49.10000 %
Epoch 253 of 2000 took 1.602s
  training loss:		0.067894
  validation loss:		0.073819
  validation accuracy:		49.15999 %
Epoch 254 of 2000 took 1.604s
  training loss:		0.067887
  validation loss:		0.073792
  validation accuracy:		49.18000 %
Epoch 255 of 2000 took 1.608s
  training loss:		0.067870
  validation loss:		0.073805
  validation accuracy:		49.11999 %
Epoch 256 of 2000 took 1.598s
  training loss:		0.067860
  validation loss:		0.073825
  validation accuracy:		49.16000 %
Epoch 257 of 2000 took 1.590s
  training loss:		0.067848
  validation loss:		0.073808
  validation accuracy:		49.15999 %
Epoch 258 of 2000 took 1.603s
  training loss:		0.067837
  validation loss:		0.073806
  validation accuracy:		49.11999 %
Epoch 259 of 2000 took 1.594s
  training loss:		0.067822
  validation loss:		0.073810
  validation accuracy:		49.22000 %
Epoch 260 of 2000 took 1.592s
  training loss:		0.067811
  validation loss:		0.073818
  validation accuracy:		49.20000 %
Epoch 261 of 2000 took 1.596s
  training loss:		0.067800
  validation loss:		0.073805
  validation accuracy:		49.18000 %
Epoch 262 of 2000 took 1.617s
  training loss:		0.067788
  validation loss:		0.073813
  validation accuracy:		49.24000 %
Epoch 263 of 2000 took 1.600s
  training loss:		0.067777
  validation loss:		0.073805
  validation accuracy:		49.25999 %
Epoch 264 of 2000 took 1.623s
  training loss:		0.067767
  validation loss:		0.073817
  validation accuracy:		49.21999 %
Epoch 265 of 2000 took 1.605s
  training loss:		0.067756
  validation loss:		0.073815
  validation accuracy:		49.21999 %
Epoch 266 of 2000 took 1.611s
  training loss:		0.067744
  validation loss:		0.073804
  validation accuracy:		49.20000 %
Epoch 267 of 2000 took 1.602s
  training loss:		0.067733
  validation loss:		0.073809
  validation accuracy:		49.21999 %
Epoch 268 of 2000 took 1.615s
  training loss:		0.067722
  validation loss:		0.073816
  validation accuracy:		49.25999 %
Epoch 269 of 2000 took 1.609s
  training loss:		0.067713
  validation loss:		0.073817
  validation accuracy:		49.27999 %
Epoch 270 of 2000 took 1.626s
  training loss:		0.067697
  validation loss:		0.073825
  validation accuracy:		49.33999 %
Epoch 271 of 2000 took 1.599s
  training loss:		0.067691
  validation loss:		0.073823
  validation accuracy:		49.22000 %
Epoch 272 of 2000 took 1.594s
  training loss:		0.067676
  validation loss:		0.073832
  validation accuracy:		49.34000 %
Epoch 273 of 2000 took 1.599s
  training loss:		0.067668
  validation loss:		0.073826
  validation accuracy:		49.25999 %
Epoch 274 of 2000 took 1.597s
  training loss:		0.067656
  validation loss:		0.073839
  validation accuracy:		49.25999 %
Epoch 275 of 2000 took 1.615s
  training loss:		0.067648
  validation loss:		0.073842
  validation accuracy:		49.29999 %
Epoch 276 of 2000 took 1.610s
  training loss:		0.067634
  validation loss:		0.073861
  validation accuracy:		49.30000 %
Epoch 277 of 2000 took 1.616s
  training loss:		0.067625
  validation loss:		0.073839
  validation accuracy:		49.31999 %
Epoch 278 of 2000 took 1.599s
  training loss:		0.067613
  validation loss:		0.073874
  validation accuracy:		49.31999 %
Epoch 279 of 2000 took 1.602s
  training loss:		0.067603
  validation loss:		0.073836
  validation accuracy:		49.35999 %
Epoch 280 of 2000 took 1.601s
  training loss:		0.067591
  validation loss:		0.073872
  validation accuracy:		49.32000 %
Epoch 281 of 2000 took 1.611s
  training loss:		0.067583
  validation loss:		0.073864
  validation accuracy:		49.29999 %
Epoch 282 of 2000 took 1.596s
  training loss:		0.067574
  validation loss:		0.073858
  validation accuracy:		49.48000 %
Epoch 283 of 2000 took 1.595s
  training loss:		0.067561
  validation loss:		0.073878
  validation accuracy:		49.34000 %
Epoch 284 of 2000 took 1.605s
  training loss:		0.067551
  validation loss:		0.073840
  validation accuracy:		49.37999 %
Epoch 285 of 2000 took 1.615s
  training loss:		0.067539
  validation loss:		0.073885
  validation accuracy:		49.31999 %
Epoch 286 of 2000 took 1.619s
  training loss:		0.067527
  validation loss:		0.073863
  validation accuracy:		49.23999 %
Epoch 287 of 2000 took 1.603s
  training loss:		0.067516
  validation loss:		0.073851
  validation accuracy:		49.38000 %
Epoch 288 of 2000 took 1.602s
  training loss:		0.067509
  validation loss:		0.073858
  validation accuracy:		49.38000 %
Epoch 289 of 2000 took 1.594s
  training loss:		0.067496
  validation loss:		0.073878
  validation accuracy:		49.34000 %
Epoch 290 of 2000 took 1.593s
  training loss:		0.067487
  validation loss:		0.073893
  validation accuracy:		49.30000 %
Epoch 291 of 2000 took 1.613s
  training loss:		0.067478
  validation loss:		0.073868
  validation accuracy:		49.34000 %
Epoch 292 of 2000 took 1.591s
  training loss:		0.067464
  validation loss:		0.073885
  validation accuracy:		49.36000 %
Epoch 293 of 2000 took 1.594s
  training loss:		0.067454
  validation loss:		0.073893
  validation accuracy:		49.38000 %
Epoch 294 of 2000 took 1.592s
  training loss:		0.067445
  validation loss:		0.073868
  validation accuracy:		49.38000 %
Epoch 295 of 2000 took 1.598s
  training loss:		0.067433
  validation loss:		0.073909
  validation accuracy:		49.30000 %
Epoch 296 of 2000 took 1.588s
  training loss:		0.067426
  validation loss:		0.073902
  validation accuracy:		49.34000 %
Epoch 297 of 2000 took 1.594s
  training loss:		0.067414
  validation loss:		0.073916
  validation accuracy:		49.34000 %
Epoch 298 of 2000 took 1.591s
  training loss:		0.067404
  validation loss:		0.073914
  validation accuracy:		49.38000 %
Epoch 299 of 2000 took 1.589s
  training loss:		0.067392
  validation loss:		0.073908
  validation accuracy:		49.38000 %
Epoch 300 of 2000 took 1.590s
  training loss:		0.067383
  validation loss:		0.073930
  validation accuracy:		49.34000 %
Epoch 301 of 2000 took 1.589s
  training loss:		0.067375
  validation loss:		0.073930
  validation accuracy:		49.44000 %
Epoch 302 of 2000 took 1.592s
  training loss:		0.067364
  validation loss:		0.073906
  validation accuracy:		49.36000 %
Epoch 303 of 2000 took 1.588s
  training loss:		0.067352
  validation loss:		0.073913
  validation accuracy:		49.48000 %
Epoch 304 of 2000 took 1.591s
  training loss:		0.067341
  validation loss:		0.073951
  validation accuracy:		49.36000 %
Epoch 305 of 2000 took 1.590s
  training loss:		0.067335
  validation loss:		0.073932
  validation accuracy:		49.34000 %
Epoch 306 of 2000 took 1.589s
  training loss:		0.067321
  validation loss:		0.073921
  validation accuracy:		49.34000 %
Epoch 307 of 2000 took 1.588s
  training loss:		0.067312
  validation loss:		0.073932
  validation accuracy:		49.32000 %
Epoch 308 of 2000 took 1.590s
  training loss:		0.067303
  validation loss:		0.073932
  validation accuracy:		49.38000 %
Epoch 309 of 2000 took 1.592s
  training loss:		0.067291
  validation loss:		0.073948
  validation accuracy:		49.28000 %
Epoch 310 of 2000 took 1.590s
  training loss:		0.067281
  validation loss:		0.073966
  validation accuracy:		49.24000 %
Epoch 311 of 2000 took 1.592s
  training loss:		0.067273
  validation loss:		0.073945
  validation accuracy:		49.36000 %
Epoch 312 of 2000 took 1.592s
  training loss:		0.067262
  validation loss:		0.073932
  validation accuracy:		49.50000 %
Epoch 313 of 2000 took 1.591s
  training loss:		0.067252
  validation loss:		0.073941
  validation accuracy:		49.42001 %
Epoch 314 of 2000 took 1.588s
  training loss:		0.067243
  validation loss:		0.073947
  validation accuracy:		49.46000 %
Epoch 315 of 2000 took 1.588s
  training loss:		0.067236
  validation loss:		0.073950
  validation accuracy:		49.38000 %
Epoch 316 of 2000 took 1.592s
  training loss:		0.067225
  validation loss:		0.073975
  validation accuracy:		49.32000 %
Epoch 317 of 2000 took 1.589s
  training loss:		0.067215
  validation loss:		0.073982
  validation accuracy:		49.36000 %
Epoch 318 of 2000 took 1.591s
  training loss:		0.067206
  validation loss:		0.073958
  validation accuracy:		49.40000 %
Epoch 319 of 2000 took 1.590s
  training loss:		0.067196
  validation loss:		0.073965
  validation accuracy:		49.40000 %
Epoch 320 of 2000 took 1.586s
  training loss:		0.067188
  validation loss:		0.073989
  validation accuracy:		49.36000 %
Epoch 321 of 2000 took 1.594s
  training loss:		0.067176
  validation loss:		0.073990
  validation accuracy:		49.30000 %
Epoch 322 of 2000 took 1.597s
  training loss:		0.067167
  validation loss:		0.073998
  validation accuracy:		49.24000 %
Epoch 323 of 2000 took 1.607s
  training loss:		0.067156
  validation loss:		0.073994
  validation accuracy:		49.29999 %
Epoch 324 of 2000 took 1.599s
  training loss:		0.067146
  validation loss:		0.073979
  validation accuracy:		49.42000 %
Epoch 325 of 2000 took 1.597s
  training loss:		0.067136
  validation loss:		0.074010
  validation accuracy:		49.32000 %
Epoch 326 of 2000 took 1.591s
  training loss:		0.067127
  validation loss:		0.073999
  validation accuracy:		49.22000 %
Epoch 327 of 2000 took 1.601s
  training loss:		0.067119
  validation loss:		0.074014
  validation accuracy:		49.26000 %
Epoch 328 of 2000 took 1.602s
  training loss:		0.067110
  validation loss:		0.074027
  validation accuracy:		49.28000 %
Epoch 329 of 2000 took 1.595s
  training loss:		0.067098
  validation loss:		0.073990
  validation accuracy:		49.32000 %
Epoch 330 of 2000 took 1.605s
  training loss:		0.067091
  validation loss:		0.073998
  validation accuracy:		49.38000 %
Epoch 331 of 2000 took 1.605s
  training loss:		0.067083
  validation loss:		0.074028
  validation accuracy:		49.32000 %
Epoch 332 of 2000 took 1.611s
  training loss:		0.067072
  validation loss:		0.074000
  validation accuracy:		49.32000 %
Epoch 333 of 2000 took 1.605s
  training loss:		0.067063
  validation loss:		0.074010
  validation accuracy:		49.36000 %
Epoch 334 of 2000 took 1.599s
  training loss:		0.067053
  validation loss:		0.074031
  validation accuracy:		49.28000 %
Epoch 335 of 2000 took 1.608s
  training loss:		0.067046
  validation loss:		0.074014
  validation accuracy:		49.35999 %
Epoch 336 of 2000 took 1.623s
  training loss:		0.067034
  validation loss:		0.074055
  validation accuracy:		49.36000 %
Epoch 337 of 2000 took 1.597s
  training loss:		0.067024
  validation loss:		0.074019
  validation accuracy:		49.32000 %
Epoch 338 of 2000 took 1.590s
  training loss:		0.067016
  validation loss:		0.074021
  validation accuracy:		49.43999 %
Epoch 339 of 2000 took 1.589s
  training loss:		0.067006
  validation loss:		0.074059
  validation accuracy:		49.38000 %
Epoch 340 of 2000 took 1.591s
  training loss:		0.066997
  validation loss:		0.074026
  validation accuracy:		49.50000 %
Epoch 341 of 2000 took 1.591s
  training loss:		0.066991
  validation loss:		0.074038
  validation accuracy:		49.42000 %
Epoch 342 of 2000 took 1.602s
  training loss:		0.066980
  validation loss:		0.074067
  validation accuracy:		49.34000 %
Epoch 343 of 2000 took 1.594s
  training loss:		0.066970
  validation loss:		0.074036
  validation accuracy:		49.44000 %
Epoch 344 of 2000 took 1.612s
  training loss:		0.066962
  validation loss:		0.074059
  validation accuracy:		49.40000 %
Epoch 345 of 2000 took 1.607s
  training loss:		0.066951
  validation loss:		0.074043
  validation accuracy:		49.42000 %
Epoch 346 of 2000 took 1.604s
  training loss:		0.066943
  validation loss:		0.074059
  validation accuracy:		49.27999 %
Epoch 347 of 2000 took 1.596s
  training loss:		0.066934
  validation loss:		0.074043
  validation accuracy:		49.42000 %
Epoch 348 of 2000 took 1.606s
  training loss:		0.066927
  validation loss:		0.074043
  validation accuracy:		49.48000 %
Epoch 349 of 2000 took 1.603s
  training loss:		0.066916
  validation loss:		0.074049
  validation accuracy:		49.48000 %
Epoch 350 of 2000 took 1.607s
  training loss:		0.066909
  validation loss:		0.074091
  validation accuracy:		49.31999 %
Epoch 351 of 2000 took 1.589s
  training loss:		0.066899
  validation loss:		0.074042
  validation accuracy:		49.45999 %
Epoch 352 of 2000 took 1.589s
  training loss:		0.066890
  validation loss:		0.074077
  validation accuracy:		49.31999 %
Epoch 353 of 2000 took 1.590s
  training loss:		0.066883
  validation loss:		0.074083
  validation accuracy:		49.31999 %
Epoch 354 of 2000 took 1.591s
  training loss:		0.066872
  validation loss:		0.074087
  validation accuracy:		49.44000 %
Epoch 355 of 2000 took 1.592s
  training loss:		0.066863
  validation loss:		0.074096
  validation accuracy:		49.31999 %
Epoch 356 of 2000 took 1.588s
  training loss:		0.066853
  validation loss:		0.074088
  validation accuracy:		49.40000 %
Epoch 357 of 2000 took 1.590s
  training loss:		0.066847
  validation loss:		0.074072
  validation accuracy:		49.40000 %
Epoch 358 of 2000 took 1.596s
  training loss:		0.066840
  validation loss:		0.074082
  validation accuracy:		49.43999 %
Epoch 359 of 2000 took 1.588s
  training loss:		0.066829
  validation loss:		0.074108
  validation accuracy:		49.30000 %
Epoch 360 of 2000 took 1.589s
  training loss:		0.066819
  validation loss:		0.074077
  validation accuracy:		49.44000 %
Epoch 361 of 2000 took 1.588s
  training loss:		0.066810
  validation loss:		0.074086
  validation accuracy:		49.51999 %
Epoch 362 of 2000 took 1.592s
  training loss:		0.066804
  validation loss:		0.074083
  validation accuracy:		49.50000 %
Epoch 363 of 2000 took 1.590s
  training loss:		0.066795
  validation loss:		0.074115
  validation accuracy:		49.42000 %
Epoch 364 of 2000 took 1.587s
  training loss:		0.066786
  validation loss:		0.074119
  validation accuracy:		49.37999 %
Epoch 365 of 2000 took 1.588s
  training loss:		0.066777
  validation loss:		0.074085
  validation accuracy:		49.57999 %
Epoch 366 of 2000 took 1.593s
  training loss:		0.066769
  validation loss:		0.074129
  validation accuracy:		49.48000 %
Epoch 367 of 2000 took 1.594s
  training loss:		0.066762
  validation loss:		0.074105
  validation accuracy:		49.52000 %
Epoch 368 of 2000 took 1.599s
  training loss:		0.066752
  validation loss:		0.074143
  validation accuracy:		49.48000 %
Epoch 369 of 2000 took 1.602s
  training loss:		0.066746
  validation loss:		0.074115
  validation accuracy:		49.50000 %
Epoch 370 of 2000 took 1.600s
  training loss:		0.066740
  validation loss:		0.074164
  validation accuracy:		49.39999 %
Epoch 371 of 2000 took 1.597s
  training loss:		0.066730
  validation loss:		0.074156
  validation accuracy:		49.40000 %
Epoch 372 of 2000 took 1.597s
  training loss:		0.066723
  validation loss:		0.074129
  validation accuracy:		49.55999 %
Epoch 373 of 2000 took 1.597s
  training loss:		0.066714
  validation loss:		0.074133
  validation accuracy:		49.58000 %
Epoch 374 of 2000 took 1.602s
  training loss:		0.066706
  validation loss:		0.074157
  validation accuracy:		49.50000 %
Epoch 375 of 2000 took 1.601s
  training loss:		0.066698
  validation loss:		0.074151
  validation accuracy:		49.57999 %
Epoch 376 of 2000 took 1.607s
  training loss:		0.066688
  validation loss:		0.074150
  validation accuracy:		49.45999 %
Epoch 377 of 2000 took 1.601s
  training loss:		0.066680
  validation loss:		0.074149
  validation accuracy:		49.62000 %
Epoch 378 of 2000 took 1.600s
  training loss:		0.066675
  validation loss:		0.074190
  validation accuracy:		49.33999 %
Epoch 379 of 2000 took 1.600s
  training loss:		0.066664
  validation loss:		0.074178
  validation accuracy:		49.48000 %
Epoch 380 of 2000 took 1.601s
  training loss:		0.066657
  validation loss:		0.074185
  validation accuracy:		49.51999 %
Epoch 381 of 2000 took 1.603s
  training loss:		0.066649
  validation loss:		0.074179
  validation accuracy:		49.52000 %
Epoch 382 of 2000 took 1.603s
  training loss:		0.066639
  validation loss:		0.074191
  validation accuracy:		49.52000 %
Epoch 383 of 2000 took 1.611s
  training loss:		0.066631
  validation loss:		0.074175
  validation accuracy:		49.63999 %
Epoch 384 of 2000 took 1.603s
  training loss:		0.066621
  validation loss:		0.074217
  validation accuracy:		49.45999 %
Epoch 385 of 2000 took 1.600s
  training loss:		0.066613
  validation loss:		0.074203
  validation accuracy:		49.52000 %
Epoch 386 of 2000 took 1.599s
  training loss:		0.066604
  validation loss:		0.074190
  validation accuracy:		49.51999 %
Epoch 387 of 2000 took 1.599s
  training loss:		0.066598
  validation loss:		0.074211
  validation accuracy:		49.44000 %
Epoch 388 of 2000 took 1.599s
  training loss:		0.066588
  validation loss:		0.074205
  validation accuracy:		49.43999 %
Epoch 389 of 2000 took 1.599s
  training loss:		0.066582
  validation loss:		0.074220
  validation accuracy:		49.40000 %
Epoch 390 of 2000 took 1.604s
  training loss:		0.066573
  validation loss:		0.074223
  validation accuracy:		49.48001 %
Epoch 391 of 2000 took 1.600s
  training loss:		0.066562
  validation loss:		0.074226
  validation accuracy:		49.48000 %
Epoch 392 of 2000 took 1.607s
  training loss:		0.066558
  validation loss:		0.074224
  validation accuracy:		49.50000 %
Epoch 393 of 2000 took 1.600s
  training loss:		0.066548
  validation loss:		0.074236
  validation accuracy:		49.46000 %
Epoch 394 of 2000 took 1.598s
  training loss:		0.066540
  validation loss:		0.074256
  validation accuracy:		49.39999 %
Epoch 395 of 2000 took 1.601s
  training loss:		0.066534
  validation loss:		0.074261
  validation accuracy:		49.45999 %
Epoch 396 of 2000 took 1.600s
  training loss:		0.066526
  validation loss:		0.074250
  validation accuracy:		49.54000 %
Epoch 397 of 2000 took 1.638s
  training loss:		0.066517
  validation loss:		0.074275
  validation accuracy:		49.49999 %
Epoch 398 of 2000 took 1.613s
  training loss:		0.066509
  validation loss:		0.074253
  validation accuracy:		49.48000 %
Epoch 399 of 2000 took 1.608s
  training loss:		0.066503
  validation loss:		0.074282
  validation accuracy:		49.49999 %
Epoch 400 of 2000 took 1.609s
  training loss:		0.066492
  validation loss:		0.074292
  validation accuracy:		49.43999 %
Epoch 401 of 2000 took 1.613s
  training loss:		0.066485
  validation loss:		0.074266
  validation accuracy:		49.51999 %
Epoch 402 of 2000 took 1.608s
  training loss:		0.066479
  validation loss:		0.074303
  validation accuracy:		49.45999 %
Epoch 403 of 2000 took 1.631s
  training loss:		0.066471
  validation loss:		0.074282
  validation accuracy:		49.36000 %
Epoch 404 of 2000 took 1.605s
  training loss:		0.066463
  validation loss:		0.074289
  validation accuracy:		49.55999 %
Epoch 405 of 2000 took 1.624s
  training loss:		0.066451
  validation loss:		0.074325
  validation accuracy:		49.39999 %
Epoch 406 of 2000 took 1.619s
  training loss:		0.066447
  validation loss:		0.074310
  validation accuracy:		49.43999 %
Epoch 407 of 2000 took 1.619s
  training loss:		0.066438
  validation loss:		0.074306
  validation accuracy:		49.52000 %
Epoch 408 of 2000 took 1.614s
  training loss:		0.066431
  validation loss:		0.074340
  validation accuracy:		49.41999 %
Epoch 409 of 2000 took 1.613s
  training loss:		0.066421
  validation loss:		0.074319
  validation accuracy:		49.55999 %
Epoch 410 of 2000 took 1.624s
  training loss:		0.066416
  validation loss:		0.074330
  validation accuracy:		49.51999 %
Epoch 411 of 2000 took 1.608s
  training loss:		0.066406
  validation loss:		0.074328
  validation accuracy:		49.49999 %
Epoch 412 of 2000 took 1.600s
  training loss:		0.066399
  validation loss:		0.074358
  validation accuracy:		49.43999 %
Epoch 413 of 2000 took 1.601s
  training loss:		0.066393
  validation loss:		0.074365
  validation accuracy:		49.38000 %
Epoch 414 of 2000 took 1.599s
  training loss:		0.066384
  validation loss:		0.074329
  validation accuracy:		49.50000 %
Epoch 415 of 2000 took 1.616s
  training loss:		0.066379
  validation loss:		0.074347
  validation accuracy:		49.43999 %
Epoch 416 of 2000 took 1.622s
  training loss:		0.066366
  validation loss:		0.074347
  validation accuracy:		49.55999 %
Epoch 417 of 2000 took 1.602s
  training loss:		0.066363
  validation loss:		0.074345
  validation accuracy:		49.48000 %
Epoch 418 of 2000 took 1.611s
  training loss:		0.066355
  validation loss:		0.074366
  validation accuracy:		49.44000 %
Epoch 419 of 2000 took 1.611s
  training loss:		0.066347
  validation loss:		0.074369
  validation accuracy:		49.40000 %
Epoch 420 of 2000 took 1.601s
  training loss:		0.066341
  validation loss:		0.074376
  validation accuracy:		49.44000 %
Epoch 421 of 2000 took 1.601s
  training loss:		0.066332
  validation loss:		0.074376
  validation accuracy:		49.42000 %
Epoch 422 of 2000 took 1.613s
  training loss:		0.066327
  validation loss:		0.074416
  validation accuracy:		49.38000 %
Epoch 423 of 2000 took 1.601s
  training loss:		0.066318
  validation loss:		0.074417
  validation accuracy:		49.39999 %
Epoch 424 of 2000 took 1.603s
  training loss:		0.066312
  validation loss:		0.074398
  validation accuracy:		49.31999 %
Epoch 425 of 2000 took 1.612s
  training loss:		0.066303
  validation loss:		0.074411
  validation accuracy:		49.34000 %
Epoch 426 of 2000 took 1.602s
  training loss:		0.066299
  validation loss:		0.074407
  validation accuracy:		49.43999 %
Epoch 427 of 2000 took 1.608s
  training loss:		0.066293
  validation loss:		0.074410
  validation accuracy:		49.47999 %
Epoch 428 of 2000 took 1.624s
  training loss:		0.066282
  validation loss:		0.074408
  validation accuracy:		49.43999 %
Epoch 429 of 2000 took 1.603s
  training loss:		0.066277
  validation loss:		0.074406
  validation accuracy:		49.42000 %
Epoch 430 of 2000 took 1.600s
  training loss:		0.066269
  validation loss:		0.074459
  validation accuracy:		49.44000 %
Epoch 431 of 2000 took 1.599s
  training loss:		0.066263
  validation loss:		0.074438
  validation accuracy:		49.43999 %
Epoch 432 of 2000 took 1.611s
  training loss:		0.066252
  validation loss:		0.074429
  validation accuracy:		49.52000 %
Epoch 433 of 2000 took 1.622s
  training loss:		0.066248
  validation loss:		0.074472
  validation accuracy:		49.36000 %
Epoch 434 of 2000 took 1.605s
  training loss:		0.066240
  validation loss:		0.074431
  validation accuracy:		49.51999 %
Epoch 435 of 2000 took 1.598s
  training loss:		0.066236
  validation loss:		0.074481
  validation accuracy:		49.40000 %
Epoch 436 of 2000 took 1.615s
  training loss:		0.066229
  validation loss:		0.074430
  validation accuracy:		49.46000 %
Epoch 437 of 2000 took 1.610s
  training loss:		0.066223
  validation loss:		0.074428
  validation accuracy:		49.51999 %
Epoch 438 of 2000 took 1.604s
  training loss:		0.066212
  validation loss:		0.074479
  validation accuracy:		49.30000 %
Epoch 439 of 2000 took 1.625s
  training loss:		0.066209
  validation loss:		0.074428
  validation accuracy:		49.54000 %
Epoch 440 of 2000 took 1.602s
  training loss:		0.066200
  validation loss:		0.074492
  validation accuracy:		49.40000 %
Epoch 441 of 2000 took 1.604s
  training loss:		0.066191
  validation loss:		0.074463
  validat